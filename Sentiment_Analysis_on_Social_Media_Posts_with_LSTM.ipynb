{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4778db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import utils\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import stanza\n",
    "import swifter\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Dropout, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f250012b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 15:18:08 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20209ea19ae6409389ab11cb500d19e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 15:18:09 INFO: Downloaded file to C:\\Users\\Mahmoud\\stanza_resources\\resources.json\n",
      "2024-09-19 15:18:09 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-09-19 15:18:09 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2024-09-19 15:18:09 WARNING: GPU requested, but is not available!\n",
      "2024-09-19 15:18:09 INFO: Using device: cpu\n",
      "2024-09-19 15:18:09 INFO: Loading: tokenize\n",
      "2024-09-19 15:18:10 INFO: Loading: mwt\n",
      "2024-09-19 15:18:10 INFO: Loading: lemma\n",
      "2024-09-19 15:18:11 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en',processors='tokenize,lemma',use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3aa55c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding=\"ISO-8859-1\", names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8d727e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take half of the data becuase of limited resources\n",
    "df, _ = train_test_split(df, train_size=0.5, random_state=42)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22a02b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1882767628</td>\n",
       "      <td>Fri May 22 07:27:10 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Beth_Heaton</td>\n",
       "      <td>might not see me mates again  ITS FUCKIN DEPRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2004583096</td>\n",
       "      <td>Tue Jun 02 08:25:36 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TexasFella68</td>\n",
       "      <td>Will be working my A$$ off shortly. Big drug s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1573929782</td>\n",
       "      <td>Tue Apr 21 03:31:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>skmacintosh</td>\n",
       "      <td>@23graeme23 i love it  dwight is my favorite.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2071588624</td>\n",
       "      <td>Sun Jun 07 19:38:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Libbyshane</td>\n",
       "      <td>@farmreport Unless it's prune jam on fiber one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2189052875</td>\n",
       "      <td>Mon Jun 15 23:08:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanK</td>\n",
       "      <td>@RENEEinSD: That's perfect!  depending on how ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag          user  \\\n",
       "0       0  1882767628  Fri May 22 07:27:10 PDT 2009  NO_QUERY   Beth_Heaton   \n",
       "1       4  2004583096  Tue Jun 02 08:25:36 PDT 2009  NO_QUERY  TexasFella68   \n",
       "2       4  1573929782  Tue Apr 21 03:31:16 PDT 2009  NO_QUERY   skmacintosh   \n",
       "3       4  2071588624  Sun Jun 07 19:38:09 PDT 2009  NO_QUERY    Libbyshane   \n",
       "4       4  2189052875  Mon Jun 15 23:08:09 PDT 2009  NO_QUERY         RyanK   \n",
       "\n",
       "                                                text  \n",
       "0  might not see me mates again  ITS FUCKIN DEPRE...  \n",
       "1  Will be working my A$$ off shortly. Big drug s...  \n",
       "2      @23graeme23 i love it  dwight is my favorite.  \n",
       "3  @farmreport Unless it's prune jam on fiber one...  \n",
       "4  @RENEEinSD: That's perfect!  depending on how ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aafc304f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "4    400212\n",
       "0    399788\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure that there is no imbalance\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6d008",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ea499eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ids', 'date', 'flag', 'user'], axis=1, inplace=True) # Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62c025e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df, column_name):\n",
    "    def extract_mention(row):\n",
    "        mentions = re.findall(r'@\\w+', row)\n",
    "        cleaned_mentions = [mention[1:] for mention in mentions]  # Remove the leading '@'\n",
    "        return \" \".join(cleaned_mentions).strip() if cleaned_mentions else None\n",
    "\n",
    "    def clean_text(row):\n",
    "        new_text = re.sub(r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+|@\\w+', '', row)\n",
    "        new_text = re.sub(r'[^A-Za-z0-9\\s]', '', new_text)\n",
    "        return new_text.strip()\n",
    "\n",
    "    df['mention'] = df[column_name].apply(lambda x: extract_mention(str(x)))\n",
    "    df['text'] = df[column_name].apply(lambda x: clean_text(str(x)))\n",
    "\n",
    "    return df\n",
    "\n",
    "df = preprocess_text(df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f60c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_texts(texts):\n",
    "    doc = nlp(texts)\n",
    "    lemmatized = []\n",
    "    \n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            lemmatized.append(word.lemma)\n",
    "    \n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "def lemmatize_df_in_batches(df, column_name, batch_size=10000):\n",
    "    num_batches = int(np.ceil(len(df) / batch_size))\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        print(f\"Processing batch {i+1} of {num_batches}...\")\n",
    "        batch_df = df[i * batch_size: (i + 1) * batch_size]\n",
    "        df.loc[i * batch_size: (i + 1) * batch_size, column_name] = batch_df[column_name].swifter.apply(lambda x: lemmatize_texts(str(x)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "574debfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f1c4b200cd4899aece0e54cbe3ccd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1271e3c67f4cc18cd0f1a4a6979166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08da0e7b98c4901ae322f4fe611f726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79858d7e883a410083cf0cfe36025ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51dde0f2efe64b2eafc91952df106551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 6 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8145e07a0e39406baa1d28bbd5d57bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d234b47920044718542c85d805b04ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb68de03d075499ea899304646fc3e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 9 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45da1d597e44a56a42fa4df9906c23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 10 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbee98deed254655af0d327399c5602c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 11 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13a5fbdee2a4d1e98284c08b5384743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 12 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a40e186b72403c9d2270e982fbfdd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 13 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095c0de77c914a08b14131cd7efe343c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 14 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6386ed796343c18c8d2edc08c1a62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 15 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6a3c20b6124cfa8e28d203fad73259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 16 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95cc904c953341168a5be1738a1598d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 17 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cec50b068244d9c9a0e0dd3209eb7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 18 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31de6b8374ff4b4297dd107716a1e554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 19 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cad78bd2359470ea5f2b82391171268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 20 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2670b6c7f6c14587a815b2460482e841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 21 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6c2c74bc52454491bc2d734cc26d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 22 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96183ec7dc0645498abf73fc3f243990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 23 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cca79be8c248a69afe072e26f09179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 24 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da1530da1924138848bc551a84bd115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 25 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50d5186afc5462e97fef8bcedc88e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 26 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d036d4cc92894c3289454cb79655ecb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 27 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d866e650c7794b599b03e03a9c498281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 28 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf38f81a10874832a243b3c1e3818c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 29 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8225032c81d346dbae2ef27466b03381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 30 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c602ae373d04ed181c4ed77dda6dbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 31 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc56ef0e8cc47dab7c9649731f9f3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 32 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173dc18da24d461db033f76b739c2dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 33 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907eb5ef8d964b3a8812ef8f351129d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 34 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2985d99355524be9b4606439f346c798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 35 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a76fb5ba207423ba51b726a34b51e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 36 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e9746f1a3e493dac8659236e210af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 37 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f4fac49bbf4bed8f6d1d3ae439a612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 38 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11854831c13d4b988ca47371c04a0bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 39 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3eaf433509a4d6a8f17e144e3a3c8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 40 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dccde4c60304e69b8c9fcec54ae16ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 41 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dbcc0bdf81640c884cff40227ef4580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 42 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515560bf58604635aafa40eec8f44f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 43 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b831cb92b16a47de81c4b5b3abde97b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 44 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27149d417a843958c10b3a50617726f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 45 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011098c5bd6b4be3be832808587f2e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 46 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a6e4d56cff4a42ae36835aa78492fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 47 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29dbaee4f3604c2ea4375b70b468135f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 48 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634768224ce241549444b7cf69c5050d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 49 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86ce546db1848c387d8b76fdf14e2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 50 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f27e093704e4b968f53a0c84de73bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 51 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfb44fb16834ab89d870452f1023f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 52 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39197a7b56fc4dc0b5695def413b846f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 53 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ebd6010106487ba50c87f140de3ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 54 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21431d7e8834970a6c013b05958b591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 55 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d704c7bd2249a590d76d34c4013237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 56 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f7518af16440159c13b52214560b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 57 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ec90948f154b47bfbf453ff4c0e6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 58 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5112b09a124427b5b48a8aea104d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 59 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d96a1062e54264a9322ac66cf35f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 60 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd4c04d7deb4c38adab9c4335051288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 61 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f07679a8364647aea6fe76309f469e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 62 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab7e48d652d4c5e9a0a0124fc6f94f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 63 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c0bb66ce3d48aea94c2df1be964347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 64 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3c32055e424d57b117638787d70117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 65 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728c5877f4c24020ad15ebaa9aca8db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 66 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff8b6ca2e574592821c77ada871861b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 67 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21767b2266a4f58aaf996aad415cea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 68 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963ad201495e4e2c939d2d9e72d124f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 69 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1327b138e90f4356b4d521c98c01eac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 70 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dede20b9a0545a49fffb2661c294ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 71 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151dc62e401c4100ac67972511e7d51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 72 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e732bc4d7c437fb6c4e2c64535b1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 73 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c5f813c1044f6c8015fe9f745a4b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 74 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9f37417f2b47439ca8b0e66c641090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 75 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a08be0847240d6afe08352e254d70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 76 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22521a43d5ac4996b3faccfd1f756b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 77 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824f6c985dfb4961b29aee16407ecef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 78 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96452478a1084e97b2fc88e7aa90af77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 79 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8120071b2b1649c29ca2185442185ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 80 of 80...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f19bae92be347a6ab399abbb9c1da06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = lemmatize_df_in_batches(df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f571aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to be used on another day\n",
    "df.to_csv('lemmatized_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d91803de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the lemattized df\n",
    "lem_df = pd.read_csv('lemmatized_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76ee2e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>mention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>might not see I mate again its fuckin depressin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>will be work my a off shortly Big drug sting g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>I love it dwight be my favorite</td>\n",
       "      <td>23graeme23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>unless its prune jam on fib one bread then I w...</td>\n",
       "      <td>farmreport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>that be perfect depend on how well you can run...</td>\n",
       "      <td>RENEEinSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799995</th>\n",
       "      <td>0</td>\n",
       "      <td>this song middle change just do not want to be...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799996</th>\n",
       "      <td>4</td>\n",
       "      <td>good luck with that</td>\n",
       "      <td>officialnjonas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799997</th>\n",
       "      <td>0</td>\n",
       "      <td>I rather average 32370</td>\n",
       "      <td>ProudGamerTweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799998</th>\n",
       "      <td>0</td>\n",
       "      <td>pickin up waitin on 2 hurry upI odeeee miss de...</td>\n",
       "      <td>misstinayao sadittysash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799999</th>\n",
       "      <td>0</td>\n",
       "      <td>home study for math wooot im so go to fail thi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target                                               text  \\\n",
       "0            0    might not see I mate again its fuckin depressin   \n",
       "1            4  will be work my a off shortly Big drug sting g...   \n",
       "2            4                    I love it dwight be my favorite   \n",
       "3            4  unless its prune jam on fib one bread then I w...   \n",
       "4            4  that be perfect depend on how well you can run...   \n",
       "...        ...                                                ...   \n",
       "799995       0  this song middle change just do not want to be...   \n",
       "799996       4                                good luck with that   \n",
       "799997       0                             I rather average 32370   \n",
       "799998       0  pickin up waitin on 2 hurry upI odeeee miss de...   \n",
       "799999       0  home study for math wooot im so go to fail thi...   \n",
       "\n",
       "                        mention  \n",
       "0                           NaN  \n",
       "1                           NaN  \n",
       "2                    23graeme23  \n",
       "3                    farmreport  \n",
       "4                     RENEEinSD  \n",
       "...                         ...  \n",
       "799995                      NaN  \n",
       "799996           officialnjonas  \n",
       "799997          ProudGamerTweet  \n",
       "799998  misstinayao sadittysash  \n",
       "799999                      NaN  \n",
       "\n",
       "[800000 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb121520",
   "metadata": {},
   "source": [
    "# --------------------------------------\n",
    "# Using Embeddings and LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13eca873",
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_df = pd.read_csv('lemmatized_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db01cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "text_list = lem_df['text'].astype(str).tolist()\n",
    "mention_list = lem_df['mention'].astype(str).tolist()\n",
    "tokenizer.fit_on_texts(text_list + mention_list)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "X_text_sequences = tokenizer.texts_to_sequences(text_list)\n",
    "X_mention_sequences = tokenizer.texts_to_sequences(mention_list)\n",
    "\n",
    "max_sequence_length_text = max(len(seq) for seq in X_text_sequences)\n",
    "max_sequence_length_mention = max(len(seq) for seq in X_mention_sequences)\n",
    "\n",
    "X_text_padded = pad_sequences(X_text_sequences, maxlen=max_sequence_length_text, padding='post')\n",
    "X_mention_padded = pad_sequences(X_mention_sequences, maxlen=max_sequence_length_mention, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab4c0c4",
   "metadata": {},
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d3abe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = np.concatenate([X_text_padded, X_mention_padded], axis=1)\n",
    "y = utils.to_categorical(lem_df['target'].values, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d92d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_combined, y, test_size = 0.3, random_state = 42)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_val, y_val, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea00ee9a",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b81af5",
   "metadata": {},
   "source": [
    "### Choosing the best structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349aa0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import random\n",
    "import os\n",
    "\n",
    "seed_value = 42\n",
    "torch.manual_seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12898146",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(lem_df['target'].values, dtype=torch.long).to('cuda')\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_combined, y.cpu().numpy(), test_size=0.3, random_state=seed_value)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=seed_value)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.long).to('cuda')\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to('cuda')\n",
    "X_cv = torch.tensor(X_cv, dtype=torch.long).to('cuda')\n",
    "y_cv = torch.tensor(y_cv, dtype=torch.long).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7649293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, lstm_hidden, num_hidden):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.num_hidden = num_hidden\n",
    "        self.lstm_hidden = lstm_hidden\n",
    "        self.embedding_dim = 200\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_hidden, batch_first=True)\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=self.lstm_hidden, out_features=self.num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(in_features=self.num_hidden, out_features=5),\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x, (hn, cn) = self.lstm(x)  # LSTM returns (output, (hn, cn))\n",
    "        x = hn[-1]  # Use the last hidden state\n",
    "        x = self.layers(x)  # Apply the rest of the layers in self.layers\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff9a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs=5, lr=0.001, weight_decay = 0):\n",
    "    model.train()  # Set the model to training mode\n",
    "    criterion = nn.CrossEntropyLoss()  # Using CrossEntropyLoss for multi-class classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)  # Forward pass\n",
    "            loss = criterion(outputs, batch_y)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "            \n",
    "            # Accumulate loss and correct predictions for this batch\n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_predictions += (predicted == batch_y).sum().item()\n",
    "\n",
    "        epoch_accuracy = correct_predictions / len(train_loader.dataset)  # Calculate epoch accuracy\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss / len(train_loader):.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        epoch_loss = 0\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)  # Move to device\n",
    "            \n",
    "            outputs = model(batch_X)  # Forward pass\n",
    "            loss = F.cross_entropy(outputs, batch_y)  # Calculate loss\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get the class with the highest probability\n",
    "            correct_predictions += (predicted == batch_y).sum().item()  # Count correct predictions\n",
    "\n",
    "    accuracy = correct_predictions / len(val_loader.dataset)  # Calculate accuracy\n",
    "    return accuracy, epoch_loss / len(val_loader)  # Return both accuracy and loss\n",
    "\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_cv, y_cv, model_class, vocab_size, lstm_hidden, num_hidden, epochs=5, lr=0.001, batch_size=512, weight_decay = 0):\n",
    "    # Use TensorDataset instead of a custom dataset\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.long), torch.tensor(y_train, dtype=torch.long))\n",
    "    val_dataset = TensorDataset(torch.tensor(X_cv, dtype=torch.long), torch.tensor(y_cv, dtype=torch.long))\n",
    "\n",
    "    # DataLoader with batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # No shuffle for validation\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = model_class(vocab_size=vocab_size, lstm_hidden=lstm_hidden, num_hidden=num_hidden).to(device)\n",
    "    train_model(model, train_loader, epochs=epochs, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy, loss = evaluate_model(model, val_loader)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}, Validation Loss: {loss:.4f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "514227d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.7021, Accuracy: 0.5003\n",
      "Epoch [2/5], Loss: 0.5568, Accuracy: 0.7007\n",
      "Epoch [3/5], Loss: 0.4430, Accuracy: 0.8023\n",
      "Epoch [4/5], Loss: 0.3812, Accuracy: 0.8358\n",
      "Epoch [5/5], Loss: 0.3285, Accuracy: 0.8633\n",
      "Validation Accuracy: 0.7720, Validation Loss: 0.5254\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "lstm_hidden=8\n",
    "num_hidden=32\n",
    "\n",
    "model = train_and_evaluate(X_train, y_train, X_cv, y_cv, LSTMModel, vocab_size, lstm_hidden, num_hidden, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a16cf1f",
   "metadata": {},
   "source": [
    "#### Since there is a huge gap between cross valdidation accuracy and training accuracy thus it is high variance (overfitting).\n",
    "#### Trying with regularization term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bc224b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.7022, Accuracy: 0.5005\n",
      "Epoch [2/5], Loss: 0.6938, Accuracy: 0.5001\n",
      "Epoch [3/5], Loss: 0.6936, Accuracy: 0.5003\n",
      "Epoch [4/5], Loss: 0.6934, Accuracy: 0.5010\n",
      "Epoch [5/5], Loss: 0.6934, Accuracy: 0.4999\n",
      "Validation Accuracy: 0.4993, Validation Loss: 0.6932\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "lstm_hidden=8\n",
    "num_hidden=32\n",
    "weight_decay = 0.000008\n",
    "model = train_and_evaluate(X_train, y_train, X_cv, y_cv, LSTMModel, vocab_size, lstm_hidden, num_hidden, epochs=epochs, batch_size=batch_size, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2534c9",
   "metadata": {},
   "source": [
    "#### Since the cross valdidation accuracy and the training accuracy is so bad then it is high bias (underfitting), trying with smaller regularization term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57c452a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.5637, Accuracy: 0.6896\n",
      "Epoch [2/5], Loss: 0.4319, Accuracy: 0.8077\n",
      "Epoch [3/5], Loss: 0.4085, Accuracy: 0.8188\n",
      "Epoch [4/5], Loss: 0.3898, Accuracy: 0.8289\n",
      "Epoch [5/5], Loss: 0.3707, Accuracy: 0.8396\n",
      "Validation Accuracy: 0.8080, Validation Loss: 0.4369\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "lstm_hidden=8\n",
    "num_hidden=32\n",
    "weight_decay = 0.000004\n",
    "model = train_and_evaluate(X_train, y_train, X_cv, y_cv, LSTMModel, vocab_size, lstm_hidden, num_hidden, epochs=epochs, batch_size=batch_size, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "217e0d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.5637, Accuracy: 0.6896\n",
      "Epoch [2/5], Loss: 0.4319, Accuracy: 0.8077\n",
      "Epoch [3/5], Loss: 0.4085, Accuracy: 0.8188\n",
      "Epoch [4/5], Loss: 0.3898, Accuracy: 0.8289\n",
      "Epoch [5/5], Loss: 0.3707, Accuracy: 0.8396\n",
      "Validation Accuracy: 0.8080, Validation Loss: 0.4369\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "lstm_hidden=8\n",
    "num_hidden=32\n",
    "weight_decay = 0.000004\n",
    "model = train_and_evaluate(X_train, y_train, X_cv, y_cv, LSTMModel, vocab_size, lstm_hidden, num_hidden, epochs=epochs, batch_size=batch_size, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea66b54",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ec85460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_final_model(model, val_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    epoch_loss = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)  # Move to device\n",
    "            \n",
    "            outputs = model(batch_X)  # Forward pass\n",
    "            loss = F.cross_entropy(outputs, batch_y)  # Calculate loss\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get the class with the highest probability\n",
    "            correct_predictions += (predicted == batch_y).sum().item()  # Count correct predictions\n",
    "            \n",
    "            # Store the predictions and true values for evaluation\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(batch_y.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / len(val_loader.dataset)\n",
    "    \n",
    "    # Generate confusion matrix and display it\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    cmd = ConfusionMatrixDisplay(cm)\n",
    "    cmd.plot()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print the classification report and F1-score\n",
    "    print('Classification report:')\n",
    "    print(classification_report(all_targets, all_preds))\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f\"F1-Score: {f1_score(all_targets, all_preds, average='weighted')}\") \n",
    "    print(f\"Average loss: {epoch_loss / len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72d6d05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81     59764\n",
      "           4       0.81      0.81      0.81     60236\n",
      "\n",
      "    accuracy                           0.81    120000\n",
      "   macro avg       0.81      0.81      0.81    120000\n",
      "weighted avg       0.81      0.81      0.81    120000\n",
      "\n",
      "Accuracy: 0.8092916666666666\n",
      "F1-Score: 0.8092923880643476\n",
      "Average loss: 0.4312155450443427\n"
     ]
    }
   ],
   "source": [
    "X_test = torch.tensor(X_test, dtype=torch.long).to('cuda')\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to('cuda')\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "evaluate_final_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a7b710",
   "metadata": {},
   "source": [
    "### The model did well on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af795eaa",
   "metadata": {},
   "source": [
    "# Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032d6da1",
   "metadata": {},
   "source": [
    "### Project Overview:\n",
    "This project involves building a sentiment classification model using an LSTM (Long Short-Term Memory) neural network. The goal is to classify text data into different sentiment categories. The model was trained and evaluated on a large dataset, focusing on improving its ability to accurately classify sentiments by optimizing hyperparameters and applying regularization to prevent overfitting.\n",
    "\n",
    "### Steps to Build the Model:\n",
    "#### Data Preprocessing:\n",
    "\n",
    "The text data was first converted into vector representations using Tensor tokenizer. This step ensures that the text data can be fed into the LSTM model.\n",
    "The dataset was split into training and validation sets to monitor model performance during training.\n",
    "\n",
    "#### Model Architecture:\n",
    "LSTM Layer: The core of the model is the LSTM layer with 8 hidden units, which captures sequential dependencies in the text data.\n",
    "Fully Connected Layer: A dense layer with 32 hidden units was added after the LSTM to further process the outputs.\n",
    "The model was trained for 5 epochs (due to limited computation resources) with a batch size of 128.\n",
    "\n",
    "#### Initial Training:\n",
    "The model was initially trained without regularization. The training process showed that the model achieved a high training accuracy (86.33%) but a significantly lower validation accuracy (77.20%). This gap indicated overfitting, where the model performed well on training data but struggled on unseen validation data.\n",
    "\n",
    "#### Regularization:\n",
    "To address overfitting, a regularization term (weight_decay) was introduced to the loss function. This term penalizes large weights in the model, encouraging it to generalize better.\n",
    "However, using too strong a regularization (weight decay = 0.000008) led to underfitting, where both training and validation accuracies stagnated around 50%, indicating high bias.\n",
    "After fine-tuning the regularization term to 0.000004, the model's performance improved, achieving a validation accuracy of 80.80% and reducing the loss to 0.4369.\n",
    "\n",
    "#### Final Model Performance:\n",
    "The final model was evaluated on a test set using the following metrics:\n",
    "\n",
    "##### Confusion Matrix: The confusion matrix provides insight into how well the model distinguishes between sentiment classes. The balanced confusion matrix showed that the model performs equally well on both classes.\n",
    "\n",
    "##### Classification Report: The model's performance for each sentiment class is as follows:\n",
    "\n",
    "Class 0 (Negative Sentiment): Precision, recall, and F1-score were all 0.81, indicating that the model is equally effective in correctly classifying negative sentiments.\n",
    "Class 4 (Positive Sentiment): Similar scores were obtained for this class, with precision, recall, and F1-score at 0.81.\n",
    "The overall accuracy was 81%, and the weighted average F1-score was also 0.81.\n",
    "\n",
    "##### Loss and F1-Score:\n",
    "The average loss during testing was 0.4312, indicating that the model predictions were relatively close to the true labels.\n",
    "The F1-score of 0.81 highlights a balance between precision and recall, demonstrating the model's overall reliability in classifying both sentiment classes.\n",
    "#### Analysis and Implications:\n",
    "The model demonstrates a good ability to classify sentiment with an accuracy of 81%. This level of performance is acceptable, especially for real-world applications like sentiment analysis in social media monitoring or customer feedback analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df326126",
   "metadata": {},
   "source": [
    "### Implications of the Model's Accuracy:\n",
    "The sentiment classification model achieved an overall accuracy of 81% on the test set, which has several implications:\n",
    "\n",
    "#### Reliability in Real-World Applications:\n",
    "An accuracy of 81% indicates that the model can effectively classify sentiment in a substantial portion of cases. This level of accuracy makes it suitable for practical applications like social media sentiment analysis, customer feedback evaluation, and brand monitoring, where distinguishing between positive and negative sentiments can influence decision-making.\n",
    "\n",
    "#### Potential for Business Insights:\n",
    "The model's performance can be leveraged to derive insights into customer opinions, market trends, and public perception. Businesses can use this information to make informed decisions, improve products or services, and enhance customer engagement strategies.\n",
    "\n",
    "#### Understanding Limitations:\n",
    "While 81% accuracy is promising, it also indicates that there is room for improvement. The remaining 19% of cases may result in misclassification, which could lead to incorrect business decisions or insights if not addressed. Understanding the nature of these misclassifications is crucial for refining the model.\n",
    "\n",
    "#### Need for Continuous Monitoring:\n",
    "Given the evolving nature of language and sentiment expression (e.g., changes in slang, cultural references, etc.), continuous monitoring and retraining of the model are essential to maintain accuracy over time. This highlights the importance of developing a feedback loop to regularly update the model with new data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
